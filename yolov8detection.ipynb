{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1UpC3gEuI108FrqxFcI_VePDAzlCdhhVK","timestamp":1696681361870},{"file_id":"1FmQQbNVZVEgtfa1A6vUt90gttxegsf3Q","timestamp":1696681323874}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!unzip /content/drive/MyDrive/changed_dataset.zip"],"metadata":{"id":"UbPkUZNtWzSx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yq7Y1ZefVDA2"},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/config.yaml\" \"/content\""],"metadata":{"id":"7IHLb66TVjSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"0dQkJoPIoaEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/Saved_Weights/best0.pt\" \"/content\""],"metadata":{"id":"2FHnO7LcVa0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","from ultralytics import YOLO\n","\n","\n","# Load a model\n","model = YOLO(\"/content/drive/MyDrive/last.pt\")\n","\n","# Use the model\n","results = model.train(data=\"/content/config.yaml\",epochs=10,project=\"FoodDetect\",name=\"Food10s\")  # train the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Juf4vzUPVM98","outputId":"84c95057-a93e-4d5d-aa07-1ed73a76c16b","executionInfo":{"status":"ok","timestamp":1686992560524,"user_tz":-330,"elapsed":7635783,"user":{"displayName":"Shayan Khan","userId":"01817366261107017378"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.118 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/last.pt, data=/content/config.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=FoodDetect, name=Food10s, exist_ok=False, pretrained=False, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=FoodDetect/Food10s\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 37.7MB/s]\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8727598  ultralytics.nn.modules.head.Detect           [10, [320, 640, 640]]         \n","Model summary: 365 layers, 68162238 parameters, 68162222 gradients\n","\n","Transferred 595/595 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir FoodDetect/Food10s', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 208MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/labels/train... 9816 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9816/9816 [00:07<00:00, 1259.79it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/labels/validation... 50 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 1782.19it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/labels/validation.cache\n","Plotting labels to FoodDetect/Food10s/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mFoodDetect/Food10s\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      13.6G     0.7258     0.4947      1.167         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:40<00:00,  1.24s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.40s/it]\n","                   all         50         85       0.92      0.944       0.96      0.808\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      14.2G     0.7498     0.5409      1.179         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:30<00:00,  1.22s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]\n","                   all         50         85       0.88      0.886      0.968      0.772\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      14.1G     0.7659     0.5777      1.189         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:26<00:00,  1.22s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.04it/s]\n","                   all         50         85        0.9      0.922      0.951      0.772\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      14.2G     0.7704     0.5809      1.196         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:26<00:00,  1.22s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.04it/s]\n","                   all         50         85      0.943      0.941      0.974      0.769\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      14.2G     0.7719     0.5754      1.197         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:25<00:00,  1.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.09it/s]\n","                   all         50         85      0.874      0.938      0.967      0.784\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      14.2G     0.7552     0.5527      1.183         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:24<00:00,  1.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.19s/it]\n","                   all         50         85      0.958      0.968      0.982      0.806\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      14.2G     0.7408       0.53      1.172         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:24<00:00,  1.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.08it/s]\n","                   all         50         85      0.893      0.912       0.96      0.814\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      14.2G     0.7279     0.5093      1.171         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:24<00:00,  1.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.09it/s]\n","                   all         50         85      0.956       0.99      0.981      0.822\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      14.2G     0.7163     0.4845      1.163         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:24<00:00,  1.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.06it/s]\n","                   all         50         85      0.957      0.973      0.982      0.823\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      14.2G     0.7008     0.4638      1.146         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [12:24<00:00,  1.21s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.41s/it]\n","                   all         50         85      0.965      0.979      0.982      0.839\n","\n","10 epochs completed in 2.104 hours.\n","Optimizer stripped from FoodDetect/Food10s/weights/last.pt, 136.7MB\n","Optimizer stripped from FoodDetect/Food10s/weights/best.pt, 136.7MB\n","\n","Validating FoodDetect/Food10s/weights/best.pt...\n","Ultralytics YOLOv8.0.118 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 268 layers, 68133198 parameters, 0 gradients\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]\n","                   all         50         85      0.965      0.979      0.982       0.84\n","           alooparatha         50          6      0.983          1      0.995      0.725\n","              rasgulla         50         25          1      0.962      0.995      0.879\n","               biryani         50          5      0.982          1      0.995       0.89\n","          chickentikka         50          6          1      0.899      0.995      0.846\n","           palakpaneer         50          5      0.929          1      0.995      0.959\n","                  poha         50          5      0.977          1      0.995      0.741\n","               khichdi         50          5      0.973          1      0.995      0.855\n","              omelette         50          6      0.949          1      0.995       0.95\n","             plainrice         50          7      0.862          1      0.889      0.763\n","               chapati         50         15      0.994      0.933      0.976      0.795\n","Speed: 1.6ms preprocess, 26.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1mFoodDetect/Food10s\u001b[0m\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"JMeVZ-8lIBKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/FoodDetect\" \"/content/drive/MyDrive\""],"metadata":{"id":"fycjI8z6EjV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","from ultralytics import YOLO\n","\n","\n","# Load a model\n","model = YOLO(\"/content/FoodDetect/Food10s/weights/best.pt\")\n","\n","# Use the model\n","results = model.val(data=\"/content/config.yaml\", split=\"test\")  # train the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0ogrXu4mfdY","executionInfo":{"status":"ok","timestamp":1686992981407,"user_tz":-330,"elapsed":226536,"user":{"displayName":"Shayan Khan","userId":"01817366261107017378"}},"outputId":"eb36cb1b-7837-4965-f636-6f1873236d50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.118 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 268 layers, 68133198 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/labels/test... 2821 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2821/2821 [00:06<00:00, 468.31it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/labels/test.cache\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [03:34<00:00,  1.21s/it]\n","                   all       2821       5064        0.9      0.856      0.919      0.734\n","           alooparatha       2821        402      0.944      0.754      0.908      0.661\n","              rasgulla       2821       1707      0.957       0.91      0.974      0.824\n","               biryani       2821        322      0.919      0.843      0.947      0.832\n","          chickentikka       2821        105      0.766      0.638        0.7       0.47\n","           palakpaneer       2821        313       0.94      0.971      0.978      0.935\n","                  poha       2821        262      0.935      0.924      0.958      0.758\n","               khichdi       2821        565       0.93      0.927      0.972      0.745\n","              omelette       2821        292      0.852      0.856      0.921      0.835\n","             plainrice       2821        426      0.919      0.908      0.937      0.705\n","               chapati       2821        670      0.841      0.832      0.892      0.575\n","Speed: 0.4ms preprocess, 67.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n"]}]},{"cell_type":"code","source":["!cp -r \"/content/runs/detect/val\" \"/content/drive/MyDrive/FoodDetect\""],"metadata":{"id":"rzHyyoaLmuX_"},"execution_count":null,"outputs":[]}]}